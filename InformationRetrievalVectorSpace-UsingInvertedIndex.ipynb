{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Blue'> Implementing a Relevance Feedback Information Retrieval System </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from itertools import islice\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the VectorSpace, Corpus, ChampionLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDescription:\n",
    "    \n",
    "    def __init__(self,docID, title, description):\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "        self.docID = docID\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadObject(name):\n",
    "    with open('objects/' + name + '.pkl', 'rb') as infile:\n",
    "        return pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorSpace = loadObject(\"vectorSpace\")\n",
    "corpus = loadObject(\"corpus\")\n",
    "champList = loadObject(\"champList\")\n",
    "inv_index_normalized = loadObject(\"inv_index_normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the methods needed to perform a free-forms query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    no_punctuation = re.sub(r'[^a-zA-Z\\s]+','',text)\n",
    "    downcase = no_punctuation.lower()\n",
    "    return downcase\n",
    "\n",
    "def tokenize(text):\n",
    "    text = normalize(text)\n",
    "    return list(text.split())\n",
    "\n",
    "def sortVector(vector):\n",
    "    sorted_vector = {k: v for k, v in sorted(vector.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_vector\n",
    "\n",
    "def normalizeVector(vector):\n",
    "    length = sqrt(sum([x**2 for x in vector.values()]))\n",
    "    normalized = {k: tfidf/length for k, tfidf in vector.items()}\n",
    "    return normalized\n",
    "\n",
    "def sortAndNormalize(vector):\n",
    "    return sortVector(normalizeVector(vector))\n",
    "\n",
    "def queryAsVector(query):\n",
    "    query = tokenize(query)\n",
    "    query_vector = {}\n",
    "\n",
    "    for term in query: #iterate through all the query terms\n",
    "        query_vector[term] = 1\n",
    "    query_vector = normalizeVector(query_vector)\n",
    "    return query_vector\n",
    "\n",
    "def innerProduct(vectorA, vectorB):\n",
    "    setA = set(vectorA.keys())\n",
    "    setB = set(vectorB.keys())\n",
    "    product = 0\n",
    "    intersection = setA.intersection(setB)\n",
    "    \n",
    "    for term in intersection:\n",
    "        product += vectorA[term] * vectorB[term]\n",
    "    return product\n",
    "\n",
    "def docIDListToTitles(docID_list):\n",
    "    result_titles = {docID: ' '.join(corpus[docID].title) for docID in docID_list}\n",
    "    return result_titles\n",
    "\n",
    "def searchVectorSpace(query_vector, vectorSpace):\n",
    "    result_innerProduct = {}\n",
    "    for docID, current_vector in vectorSpace.items():\n",
    "        inner_product = innerProduct(query_vector, current_vector)\n",
    "        if inner_product > 0:\n",
    "            result_innerProduct[docID] = inner_product\n",
    "    result_sorted_by_innerProduct = sortVector(result_innerProduct)\n",
    "    docID_list = list(result_sorted_by_innerProduct.keys())\n",
    "    result_titles = docIDListToTitles(docID_list)\n",
    "    return result_titles\n",
    "\n",
    "def union(listA, listB):\n",
    "    setA = set(listA)\n",
    "    setB = set(listB)\n",
    "    union = setA.union(setB)\n",
    "    return list(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchChampionList(query):\n",
    "    query = tokenize(query)\n",
    "    result_list = []\n",
    "    \n",
    "    for term in query:\n",
    "        result_list.append(champList[term])\n",
    "    union_result_list = reduce(union, result_list)\n",
    "    return docIDListToTitles(union_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchVectorSpaceAsInvertedIndex(query_vector, inv_index_normalized):\n",
    "    result_products = defaultdict(dict)\n",
    "\n",
    "    for term, query_tfidf in query_vector.items():\n",
    "        for docID, tfidf_normalized in inv_index_normalized[term].items():\n",
    "            result_products[docID][term] = tfidf_normalized * query_tfidf\n",
    "\n",
    "        result_innerProduct = {}\n",
    "        for docID, vector_products in result_products.items():\n",
    "            result_innerProduct[docID] = sum(vector_products.values())\n",
    "        result_innerProduct = sortVector(result_innerProduct)\n",
    "\n",
    "        result_titles = {}\n",
    "        for docID, inner_product in result_innerProduct.items():\n",
    "            result_titles[docID] = ' '.join(corpus[docID].title)\n",
    "    return result_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Relevance Feedback -> Rocchio Algorithm!!\n",
    "- #### Reasonable values might be α = 1, β = 0.75, and γ = 0 (only positive feedback with γ = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumVector(vectorA, vectorB):\n",
    "    setA = set(vectorA.keys())\n",
    "    setB = set(vectorB.keys())\n",
    "    summation = {}\n",
    "    intersection = setA.intersection(setB)\n",
    "    union = setA.union(setB)\n",
    "    \n",
    "    for component in intersection: # sum tfidf when matching keys\n",
    "        summation[component] = vectorA[component] + vectorB[component]\n",
    "\n",
    "    for component in union - intersection: # assign the right tfidf when keys do not match\n",
    "        try:\n",
    "            summation[component] = vectorA[component]\n",
    "        except KeyError:\n",
    "            summation[component] = vectorB[component]\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryUpdateRocchio(query_vector, preference, vectorSpace):\n",
    "    alpha = 1\n",
    "    beta = 0.75\n",
    "\n",
    "    # calculating sum of relevant documents\n",
    "    summation = {}\n",
    "    for docID in preference:\n",
    "        summation = sumVector(summation, vectorSpace[docID])\n",
    "\n",
    "    # implementing Rocchio algorithm\n",
    "    denominator = beta * 1/abs(len(preference))\n",
    "    centroid_Dr_multiplied_by_beta = {docID: denominator * tfidf for docID, tfidf in summation.items()}\n",
    "    query_vector_multiplied_by_alpha = {docID: alpha * tfidf for docID, tfidf in query_vector.items()}\n",
    "    new_query_vector = sumVector(query_vector_multiplied_by_alpha, centroid_Dr_multiplied_by_beta)\n",
    "    return new_query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Heuristic for the Relevance Feedback\n",
    "- #### At first iteration, use the Champion List to respond, if there are more than 50 results compute a search on the Vector Space instead\n",
    "##### Why? Well, while using the Champion Lists, we can't rank the results, thus the user must scan the whole list of results without a sense of ordering, maybe it's a little too messy like this. Maybe it's better to display few results but with an order by relevance -> search on the Vector Space instead\n",
    "- #### When the user express some preferences, move to the vector space and draft the query using the Rocchio Algorithm\n",
    "##### Why? Well, while using the Champion Lists, few terms -> few results. Maybe we need to have a search space wider than the union of the ChampionLists when we express a preference towards a set of documents to be more precise in the drafting of the query!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: \n",
    "- 1. Search for a query\n",
    "- 2. Respond to the query using Champion Lists / VectorSpace (depends on the Champion Lists result)\n",
    "- 3. Give positive feedback for some titles in the result (specifing the docIDs, separated by space)\n",
    "- 4. Use Rocchio Algorithm to draft the query from the starter point of the Vector Space\n",
    "- 5. Respond to the new query displaying only the 15 most relevant documents (just to have a nice view of the results and the cicle of iterations)\n",
    "- 6. Back to point 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchVectorSpaceSliced(query_vector, inv_index_normalized, max_length):\n",
    "    result = searchVectorSpaceAsInvertedIndex(query_vector, inv_index_normalized)\n",
    "    result_sliced = dict(islice(result.items(), max_length))\n",
    "    return result_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 15\n",
    "\n",
    "query = input(\"Insert free-form query:\")\n",
    "print()\n",
    "\n",
    "# The Rocchio algorithm perform a drafting of the query in the VectorSpace, thus we need to cast our query in a vector!\n",
    "query_vector = queryAsVector(query)\n",
    "\n",
    "result = searchChampionList(query)\n",
    "\n",
    "if len(result) > 50:\n",
    "    result = searchVectorSpaceSliced(query_vector, inv_index_normalized, max_length)\n",
    "\n",
    "[print('docID: {}, title: \"{}\"'.format(docID, title)) for docID, title in result.items()]\n",
    "preference = input(\"\\n Insert docIDs of relevant results\").split()\n",
    "\n",
    "\n",
    "preference = [int(x) for x in preference] # just a parsing from String to Integer\n",
    "\n",
    "while preference: # while preference list is not empty\n",
    "    print()\n",
    "    new_query = queryUpdateRocchio(query_vector, preference, vectorSpace)\n",
    "    result = searchVectorSpaceSliced(new_query, inv_index_normalized, max_length)\n",
    "    [print('docID: {}, title: \"{}\"'.format(docID, title)) for docID, title in result.items()]\n",
    "    query_vector = new_query\n",
    "    preference = input(\"Insert docIDs of relevant results\").split()\n",
    "    \n",
    "    preference = [int(x) for x in preference]\n",
    "    \n",
    "print(\"\\n Bye bye!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the pseudo-feedback\n",
    "- #### Perform the query as usual\n",
    "- #### Consider the first K retrieved documents in the ranking as relevant and perform Relevance Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudoFeedback(query_vector, vectorSpace, inv_index_normalized,  max_length, K):\n",
    "    result = searchVectorSpaceSliced(query_vector, inv_index_normalized, K)\n",
    "    only_first_K_considered = list(result.keys())\n",
    "    preference = only_first_K_considered\n",
    "    new_query = queryUpdateRocchio(query_vector, preference, vectorSpace)\n",
    "    result = searchVectorSpaceSliced(query_vector, inv_index_normalized, max_length)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow: \n",
    "- 1. Search for a query\n",
    "- 2. Respond to the query using pseudo-feedback\n",
    "- 3. Give positive feedback for some titles in the result (specifing the docIDs, separated by space)\n",
    "- 4. Use Rocchio Algorithm to draft the query from the starter point of the Vector Space\n",
    "- 5. Respond to the new query displaying only the 15 most relevant documents (just to have a nice view of the results and the cicle of iterations)\n",
    "- 6. Back to point 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 15\n",
    "K = 3\n",
    "\n",
    "query = input(\"Insert free-form query:\")\n",
    "print()\n",
    "query_vector = queryAsVector(query)\n",
    "\n",
    "result = pseudoFeedback(query_vector, vectorSpace, inv_index_normalized, max_length, K)\n",
    "\n",
    "[print('docID: {}, title: \"{}\"'.format(docID, title)) for docID, title in result.items()]\n",
    "preference = input(\"\\n Insert docIDs of relevant results\").split()\n",
    "\n",
    "preference = [int(x) for x in preference] # just a parsing from String to Integer\n",
    "\n",
    "while preference: # while preference list is not empty\n",
    "    print()\n",
    "    new_query = queryUpdateRocchio(query_vector, preference, vectorSpace)\n",
    "    result = searchVectorSpaceSliced(new_query, inv_index_normalized, max_length)\n",
    "    [print('docID: {}, title: \"{}\"'.format(docID, title)) for docID, title in result.items()]\n",
    "    query_vector = new_query\n",
    "    preference = input(\"Insert docIDs of relevant results\").split()\n",
    "    \n",
    "    preference = [int(x) for x in preference]\n",
    "    \n",
    "print(\"\\n Bye bye!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
